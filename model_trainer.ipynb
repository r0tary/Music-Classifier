{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import librosa \n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, add, Dense, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D,Conv1D,MaxPooling1D,Reshape\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song(path):\n",
    "    y, rate = librosa.load(path)\n",
    "    data = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    col = data.shape[1] \n",
    "    for i in range(1290,data.shape[1]):\n",
    "        data = np.delete(data,0,axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data/genres_original/'\n",
    "genres = list(os.listdir(data_dir))\n",
    "paths = []\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    curr_path = data_dir + genres[i] + '/'\n",
    "    titles = os.listdir(curr_path)\n",
    "    for title in titles:\n",
    "        paths.append((curr_path + title,i))\n",
    "\n",
    "\n",
    "rd.shuffle(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths,test_paths = train_test_split(paths,test_size=0.3)\n",
    "test_paths,val_paths = train_test_split(test_paths,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\nmodel.add(Reshape((1025,1290,1),input_shape = (1025,1290)))\\nmodel.add(Conv2D(128,kernel_size = 3,activation = 'relu'))\\nmodel.add(MaxPool2D(pool_size =(3,3)))\\nmodel.add(Conv2D(64,kernel_size = 3,activation = 'relu'))\\nmodel.add(MaxPool2D(pool_size =(3,3)))\\nmodel.add(Dropout(0.25))\\nmodel.add(Conv2D(64,kernel_size = 3,activation = 'relu'))\\nmodel.add(MaxPool2D(pool_size =(3,3)))\\nmodel.add(Conv2D(64,kernel_size = 3,activation = 'relu'))\\nmodel.add(MaxPool2D(pool_size =(3,3)))\\nmodel.add(Dropout(0.25))\\nmodel.add(Flatten())\\nmodel.add(Dense(64,activation = 'relu'))\\nmodel.add(Dense(len(genres),activation = 'softmax'))\\nmodel.summary()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = Sequential()\n",
    "model.add(Reshape((1025,1290,1),input_shape = (1025,1290)))\n",
    "model.add(Conv2D(128,kernel_size = 3,activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(3,3)))\n",
    "model.add(Conv2D(64,kernel_size = 3,activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(3,3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,kernel_size = 3,activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(3,3)))\n",
    "model.add(Conv2D(64,kernel_size = 3,activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(3,3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(len(genres),activation = 'softmax'))\n",
    "model.summary()'''\n",
    "#10 % efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 1025, 1290, 1)     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1022, 1287, 128)   2176      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 255, 321, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 255, 321, 128)     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 252, 318, 64)      131136    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 63, 79, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 63, 79, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 76, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 19, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 19, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 16, 64)        65600     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                24608     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289,450\n",
      "Trainable params: 289,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((1025, 1290,1),input_shape = (1025, 1290)))\n",
    "model.add(Conv2D(128,kernel_size = (4,4),activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(4,4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,kernel_size = (4,4),activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(4,4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,kernel_size = (4,4),activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(4,4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,kernel_size = (4,4),activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size =(4,4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dense(len(genres),activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop  = EarlyStopping(monitor = 'val_loss',patience=4,verbose=1)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, file_set):\n",
    "        self.paths = file_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.paths))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = np.array(load_song(self.paths[idx][0])).reshape((1,1025, 1290))\n",
    "        batch_y = np.array(self.paths[idx][1]).reshape((1))\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneratorTo3dim(Sequence):\n",
    "    def __init__(self, file_set):\n",
    "        self.paths = file_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.paths))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = np.stack((np.resize(load_song(self.paths[idx][0])).reshape((1,1025, 1290),new_shape=(224,224)),np.zeros((224,224)),np.zeros((224,224))),axis=2)\n",
    "        batch_y = np.array(self.paths[idx][1]).reshape((1))\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(train_paths)\n",
    "val_gen = DataGenerator(val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1025, 1290)\n"
     ]
    }
   ],
   "source": [
    "train_gen3 = DataGenerator(train_paths)\n",
    "a = train_gen3.__getitem__(0)\n",
    "print(a[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filip\\anaconda3\\lib\\site-packages\\keras\\backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699/699 [==============================] - 3367s 5s/step - loss: 2.2786 - accuracy: 0.1302 - val_loss: 2.1084 - val_accuracy: 0.1667\n",
      "Epoch 2/6\n",
      "699/699 [==============================] - 1613s 2s/step - loss: 2.1439 - accuracy: 0.1917 - val_loss: 2.0630 - val_accuracy: 0.2333\n",
      "Epoch 3/6\n",
      "699/699 [==============================] - 4847s 7s/step - loss: 1.8638 - accuracy: 0.3305 - val_loss: 1.9281 - val_accuracy: 0.2556\n",
      "Epoch 4/6\n",
      "699/699 [==============================] - 1401s 2s/step - loss: 1.7530 - accuracy: 0.3591 - val_loss: 1.6533 - val_accuracy: 0.3667\n",
      "Epoch 5/6\n",
      "699/699 [==============================] - 1388s 2s/step - loss: 1.6022 - accuracy: 0.4192 - val_loss: 1.8345 - val_accuracy: 0.3111\n",
      "Epoch 6/6\n",
      "699/699 [==============================] - 1379s 2s/step - loss: 1.5924 - accuracy: 0.4192 - val_loss: 1.5004 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d727c01100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen, \n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data = val_gen,\n",
    "                    callbacks = [early_stop]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: song_classifier_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: song_classifier_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"song_classifier_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 77s 367ms/step - loss: 1.5126 - accuracy: 0.4381\n"
     ]
    }
   ],
   "source": [
    "test_gen = DataGenerator(test_paths)\n",
    "results =model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n",
      "[36, 81, 54, 26, 79, 15, 66, 79, 11, 39]\n"
     ]
    }
   ],
   "source": [
    "gen = DataGenerator(paths)\n",
    "score = 0\n",
    "labels_score = [0 for i in range(len(genres))]\n",
    "for i in range(len(paths)):\n",
    "    a = model.predict(gen.__getitem__(i)[0],verbose = 0)\n",
    "    if gen.__getitem__(i)[1][0] == np.argmax(a):\n",
    "        labels_score[gen.__getitem__(i)[1][0]] += 1\n",
    "        score += 1\n",
    "print(score)\n",
    "print(labels_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13485529 0.00586919 0.06989498 0.19992569 0.05677962 0.04619331\n",
      "  0.07597676 0.13744643 0.02690804 0.24615061]]\n",
      "Data/genres_original/rock/rock.00024.wav\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_on_batch(test_gen.__getitem__(35)[0]))\n",
    "print(test_paths[35][0])\n",
    "print(test_gen.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for song_classifier_2\\variables\\variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21248\\3078880431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"song_classifier_2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    959\u001b[0m                         ckpt_options, options, filters)\n\u001b[0;32m    960\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         raise FileNotFoundError(\n\u001b[0m\u001b[0;32m    962\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n You may be trying to load on a different device \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;34m\"from the computational device. Consider setting the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for song_classifier_2\\variables\\variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f954d28a9e4fcff8e204dcda762acd6ec94c0129a462d401d33c39e22fb10a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
